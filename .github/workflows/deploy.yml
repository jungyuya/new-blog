# 파일 위치: .github/workflows/deploy.yml
# 최종 버전: v2025.08.09-The-Purified-Masterpiece
# 역할: Dockerfile을 유일한 빌드 주체로 삼고, 그 결과물을 이미지와 S3에 공급하며,
#       모든 단계를 자동으로 검증하는, 궁극의 최종 파이프라인

name: "Build, Push, and Deploy Full-Stack Application"

on:
  push:
    branches:
      - main

concurrency:
  group: ${{ github.ref }}
  cancel-in-progress: true

env:
  ECR_REPOSITORY: new-blog-frontend
  AWS_REGION: ${{ secrets.AWS_REGION }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
      packages: write

    steps:
      # ===================================================================================
      # Phase 1: 환경 설정 및 의존성 설치
      # ===================================================================================
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: "22"

      - name: "Setup pnpm"
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: "Install dependencies"
        run: pnpm install --frozen-lockfile

      # ===================================================================================
      # Phase 2: Docker를 통한 단일 빌드, 푸시, 그리고 결과물 추출
      # ===================================================================================
      - name: "Configure AWS Credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: "Build with Turborepo Remote Cache"
        env:
          TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
          TURBO_API: ${{ vars.TURBO_API_ENDPOINT }}
        run: pnpm exec turbo run build --filter=frontend --log-level=debug

      - name: "Login to Amazon ECR"
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: "Set up Docker Buildx"
        uses: docker/setup-buildx-action@v3

      - name: "Define Image Tag"
        id: image-def
        run: echo "TAG=$(date +%Y%m%d%H%M%S)-$(echo $GITHUB_SHA | cut -c1-7)" >> $GITHUB_OUTPUT

      - name: "Build, Push Docker Image and Export Static Assets"
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./apps/frontend/Dockerfile
          push: true
          tags: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ steps.image-def.outputs.TAG }}
          platforms: linux/arm64
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: false
          outputs: type=local,dest=./output

      # [안전장치 1] 추출된 결과물의 구조를 로그로 남겨, 문제가 생겼을 때 확인할 수 있도록 합니다.
      - name: "Verify Exported Artifacts"
        run: |
          echo "--- Verifying contents of ./output directory ---"
          ls -lR ./output

      # ===================================================================================
      # Phase 3: CDK를 통한 인프라 배포
      # ===================================================================================
      - name: "Deploy Infrastructure via CDK"
        id: cdk-deploy
        run: |
          # [핵심 최종 수정] --outputs-file의 경로를, 변덕스러운 상대 경로가 아닌,
          # CI 환경의 루트 디렉토리를 가리키는 '절대 경로'로 명시합니다.
          pnpm --filter infra exec cdk deploy --all \
            --require-approval never \
            --outputs-file ${{ github.workspace }}/apps/infra/outputs.json \
            --parameters ImageTag=${{ steps.image-def.outputs.TAG }}

      # ===================================================================================
      # Phase 4: 콘텐츠 배포 (추출된 결과물 사용)
      # ===================================================================================
      - name: "Sync Static Assets to S3"
        run: |
          set -euo pipefail
          ASSET_BUCKET_NAME=$(cat ./apps/infra/outputs.json | jq -r '.BlogInfraStack.FrontendAssetsBucketName')
          if [ -z "$ASSET_BUCKET_NAME" ] || [ "$ASSET_BUCKET_NAME" == "null" ]; then
            echo "::error::Failed to read S3 bucket name from CDK outputs."
            exit 1
          fi

          # [핵심] find 명령어로 .next/static 디렉토리를 동적으로 찾아, 경로 불일치 문제를 원천 차단합니다.
          FOUND_STATIC_DIR=$(find ./output -type d -path '*/.next/static' -print -quit)
          if [ -z "$FOUND_STATIC_DIR" ]; then
            echo "::error::No .next/static directory found in exported image output."
            exit 1
          fi

          echo "Syncing static assets from '$FOUND_STATIC_DIR' to s3://${ASSET_BUCKET_NAME}/_next/static"
          aws s3 sync "$FOUND_STATIC_DIR" "s3://${ASSET_BUCKET_NAME}/_next/static" --delete

      # ===================================================================================
      # Phase 5: CloudFront 캐시 무효화
      # ===================================================================================
      - name: "Invalidate CloudFront Cache"
        run: |
          DISTRIBUTION_ID=$(cat ./apps/infra/outputs.json | jq -r '.BlogInfraStack.CloudFrontDistributionId')
          if [ -z "$DISTRIBUTION_ID" ] || [ "$DISTRIBUTION_ID" == "null" ]; then
            echo "::error::Failed to read CloudFront distribution ID from CDK outputs."
            exit 1
          fi

          echo "Invalidating cache for distribution: $DISTRIBUTION_ID"
          aws cloudfront create-invalidation --distribution-id ${DISTRIBUTION_ID} --paths "/*"
